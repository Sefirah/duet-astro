{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import copy\n",
    "from astropy.visualization import quantity_support\n",
    "from astropy.table import Table, QTable\n",
    "import matplotlib\n",
    "import astropy.units as u\n",
    "from astroduet.config import Telescope\n",
    "from astroduet.background import background_pixel_rate\n",
    "font = {'size'   : 22}\n",
    "from astroduet.models import Simulations, fits_file, load_model_ABmag, load_model_fluence\n",
    "matplotlib.rcParams.update({'font.size': 22})\n",
    "from astroduet.lightcurve import get_lightcurve, lightcurve_through_image\n",
    "import astroduet.image_utils\n",
    "from astroduet.utils import duet_fluence_to_abmag\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do it only once\n",
    "# sims = Simulations()\n",
    "# sims.parse_emgw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_plot_lc(input_lc_file, distance=100e6*u.pc, **kwargs):\n",
    "    abtime, ab1, ab2 = load_model_ABmag(input_lc_file,\n",
    "                                        dist=distance)\n",
    "    model_lc_table_ab = QTable({'time': abtime, 'mag_D1': ab1, 'mag_D2':ab2})\n",
    "    lightcurve = get_lightcurve(input_lc_file, distance=distance, **kwargs)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    gs = plt.GridSpec(2, 1, hspace=0)\n",
    "    ax0 = plt.subplot(gs[0])\n",
    "    ax1 = plt.subplot(gs[1], sharex=ax0)\n",
    "    good = (lightcurve['snr_D1'] > 1) | (lightcurve['snr_D2'] > 1)\n",
    "    lightcurve = lightcurve[good]\n",
    "    ax0.errorbar(lightcurve['time'].value / 86400, lightcurve['mag_D1'].value, \n",
    "                 fmt='o', markersize=2, yerr=lightcurve['mag_D1_err'].value)\n",
    "    ax0.errorbar(lightcurve['time'].value / 86400, lightcurve['mag_D2'].value, \n",
    "                 fmt='o', markersize=2, yerr=lightcurve['mag_D2_err'].value)\n",
    "    ax1.scatter(lightcurve['time'].value / 86400, lightcurve['snr_D1'].value, s=2)\n",
    "    ax1.scatter(lightcurve['time'].value / 86400, lightcurve['snr_D2'].value, s=2)\n",
    "    \n",
    "    ax0.plot(model_lc_table_ab['time'] / 86400, model_lc_table_ab[f'mag_D1'])\n",
    "    ax0.plot(model_lc_table_ab['time'] / 86400, model_lc_table_ab[f'mag_D2'])\n",
    "\n",
    "    ax0.set_ylabel(\"AB mag\")\n",
    "    ax1.set_ylabel(\"S/R\")\n",
    "    ax1.set_xlabel(\"Time (d)\")\n",
    "    ax0.set_xlim([lightcurve['time'][0].value / 86400, lightcurve['time'][-1].value / 86400])\n",
    "    ymin = min(lightcurve['mag_D1'].value.min(), lightcurve['mag_D2'].value.min()) - 1\n",
    "    ymax = max(lightcurve['mag_D1'].value.max(), lightcurve['mag_D2'].value.max()) + 1\n",
    "    # Inverted ax for magnitude\n",
    "#     ax0.set_ylim([ymax, ymin])\n",
    "#    ax1.semilogx();\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_plot_lc('shock_2.5e10.dat', distance=100e6*u.pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now specifying the observing window..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_realistic_lightcurve(input_lc_file, exposure, label=None, debug=False,  \n",
    "                              observing_windows=np.array([[0, 30000]]) * u.s, \n",
    "                              final_resolution=1200 * u.s, distance=150e6*u.pc):\n",
    "    duet = Telescope()\n",
    "    # Set debug to True to dump all intermediate images.\n",
    "    lightcurve_init = \\\n",
    "        get_lightcurve(input_lc_file, exposure=exposure, observing_windows=observing_windows,\n",
    "                       distance=distance)\n",
    "    lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=exposure, \n",
    "                                                final_resolution=final_resolution, \n",
    "                                                debug=debug)\n",
    "    lightcurve = lightcurve_through_image(lightcurve_init, exposure=exposure, debug=debug)\n",
    "    \n",
    "    model_lc_table_fl = QTable(load_model_fluence(input_lc_file,\n",
    "                                                  dist=distance))\n",
    "    \n",
    "    model_lc_table_AB = QTable(load_model_ABmag(input_lc_file,\n",
    "                                                dist=distance))\n",
    "    \n",
    "    model_lc_table_fl['fluence_D1'] = model_lc_table_fl['fluence_D1'].to(u.ph / u.cm**2 / u.s)\n",
    "    model_lc_table_fl['fluence_D2'] = model_lc_table_fl['fluence_D2'].to(u.ph / u.cm**2 / u.s)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(model_lc_table_fl['time'].value / 86400, \n",
    "             model_lc_table_fl['fluence_D1'].to(u.ph / u.cm**2 / u.s).value, label=f\"init D1\",\n",
    "             color='r')\n",
    "    plt.plot(model_lc_table_fl['time'].value / 86400, \n",
    "             model_lc_table_fl['fluence_D2'].to(u.ph / u.cm**2 / u.s).value, label=f\"init D2\",\n",
    "             color='b')\n",
    "    \n",
    "    model_lc_table_fl.write(label + '_model.csv')\n",
    "    model_lc_table_AB.write(label + '_modelAB.csv')\n",
    "    \n",
    "    for lc, expo, filename in zip([lightcurve, lightcurve_rebin], [exposure, final_resolution],\n",
    "                              [label + '.csv', label + '_rebin.csv']):\n",
    "        alpha = 1\n",
    "        size = 10\n",
    "        if expo == exposure:\n",
    "            alpha = 0.3\n",
    "            size = 5\n",
    "        good1 = (lc['fluence_D1_fit'] > 0)&(lc['fluence_D1_fiterr'] < lc['fluence_D1_fit'])\n",
    "        good2 = (lc['fluence_D2_fit'] > 0)&(lc['fluence_D2_fiterr'] < lc['fluence_D2_fit'])\n",
    "        good = good1&good2\n",
    "        plt.errorbar(lc['time'].value[good] / 86400, \n",
    "                     lc['fluence_D1_fit'][good].value, \n",
    "                     yerr=lc['fluence_D1_fiterr'][good].value, fmt='o', label=f\"D1, {expo}\",\n",
    "                     alpha=alpha, color='r', markersize=size)\n",
    "        plt.errorbar(lc['time'].value[good] / 86400, \n",
    "                     lc['fluence_D2_fit'][good].value, \n",
    "                     yerr=lc['fluence_D2_fiterr'][good].value, fmt='s', label=f\"D2, {expo}\",\n",
    "                     alpha=alpha, color='b', markersize=size)\n",
    "        \n",
    "        lc[good].write(filename)\n",
    "\n",
    "    plt.xlabel(\"Time (d)\")\n",
    "    plt.ylabel(\"Fluence (ph / cm^2 / s)\")\n",
    "    plt.xlim([lightcurve['time'].value.min()/86400, \n",
    "              lightcurve['time'].value.max()/86400])\n",
    "    plt.title(label)\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"shock_5e10.dat\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[30 * 60, 900000]]) * u.s, \n",
    "                          final_resolution=2400 * u.s, \n",
    "                          distance=150e6*u.pc, label=\"shock_5e10, 150Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"kilonova_0.04.dat\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[30 * 60, 900000]]) * u.s, \n",
    "                          final_resolution=4800 * u.s, \n",
    "                          distance=150e6*u.pc, label=\"blukn_04, 150Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = Simulations()\n",
    "# s.parse_sne(list_of_simulations=['IIP', 'IIP_big', 'stripped'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"IIP_big\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[0, 1000000]]) * u.s, \n",
    "                          final_resolution=12000 * u.s, \n",
    "                          distance=300e6*u.pc, label=\"IIP_big, 300Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"IIP\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[40*60, 1000000]]) * u.s, \n",
    "                          final_resolution=24000 * u.s, \n",
    "                          distance=300e6*u.pc, label=\"IIP, 300Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"stripped\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[40*60, 300000]]) * u.s, \n",
    "                          final_resolution=1200 * u.s, \n",
    "                          distance=100e6*u.pc, label=\"stripped, 100Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"IIb\", 300 * u.s,  \n",
    "                          observing_windows=np.array([[0, 1000000]]) * u.s, \n",
    "                          final_resolution=6000 * u.s, \n",
    "                          distance=300e6*u.pc, label=\"IIb, 300Mpc\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s.parse_sne(list_of_simulations=['IIb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## In case someone wants to take a look at the debug images...\n",
    "## set debug=True in plot_realistic_lightcurves and look at them\n",
    "\n",
    "def plot_debug_images(directory):\n",
    "    from astroduet.image_utils import find, run_daophot\n",
    "    img_pickles = glob.glob(os.path.join(directory, '*.p'))\n",
    "    for img_pickle in img_pickles:\n",
    "        with open(img_pickle, 'rb') as fobj:\n",
    "            img = pickle.load(fobj)\n",
    "        image1 = img['imgD1']\n",
    " \n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.title(img_pickle)\n",
    "        plt.imshow(image1.value)\n",
    "    \n",
    "# plot_debug_images('debug_imgs_300.0s_12161320/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_realistic_lightcurve(\"shock_5e10.dat\", exposure=300 * u.s,\n",
    "                   observing_windows=np.array([[0, 90000]]) * u.s, \n",
    "                   distance=100e6*u.pc, \n",
    "                   label='shock_5e10, 100 Mpc', debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_chi_sq(f, x, s, dof=None):\n",
    "    if dof is None:\n",
    "        dof = len(f) - 1\n",
    "    return np.sum((f - x)**2 / s**2) / dof\n",
    "\n",
    "\n",
    "def fit_lightcurve(lightcurve, label='lightcurve fit', solutions=None,\n",
    "                   debug=False):\n",
    "    from astroduet.models import Simulations\n",
    "    from scipy.optimize import curve_fit\n",
    "    from scipy.interpolate import interp1d\n",
    "    from astropy.visualization import quantity_support\n",
    "    quantity_support()\n",
    "\n",
    "    if solutions is None:\n",
    "        solutions = QTable(\n",
    "            names='model,D1,D2,ratio,D1_chisq,D2_chisq,ratio_chisq,ngood'.split(','), \n",
    "            dtype=['U30', float, float, float, float, float, float, int])\n",
    "    \n",
    "    lc_files = Simulations().emgw_simulations\n",
    "\n",
    "    fluence_D1 = lightcurve['fluence_D1_fit']\n",
    "    fluence_D2 = lightcurve['fluence_D2_fit']\n",
    "    snr_D1 = lightcurve['snr_D1']\n",
    "    snr_D2 = lightcurve['snr_D2']\n",
    "    good = (fluence_D1 > 0)&(fluence_D2 > 0)&(snr_D1 > 5)&(snr_D1 > 5)\n",
    "    \n",
    "    lightcurve = lightcurve[good]\n",
    "    if len(lightcurve) < 2:\n",
    "        print(\"Lightcurve is invalid\")\n",
    "        for lc_file in lc_files:\n",
    "            solutions.add_row({'model': lc_file, 'D1': 0, 'D2': 0, 'ratio': 0, \n",
    "                               'D1_chisq': -1, 'D2_chisq': -1, 'ratio_chisq': -1,\n",
    "                               'ngood': 0})\n",
    "        return solutions\n",
    "    \n",
    "    fluence_D1 = lightcurve['fluence_D1_fit']\n",
    "    fluence_D2 = lightcurve['fluence_D2_fit']\n",
    "    times = lightcurve['time']\n",
    "    fluence_D1 = lightcurve['fluence_D1_fit']\n",
    "    fluence_D2 = lightcurve['fluence_D2_fit']\n",
    "    fluence_D1_err = lightcurve['fluence_D1_fiterr'] \n",
    "    fluence_D2_err = lightcurve['fluence_D2_fiterr'] \n",
    "\n",
    "    ratio = fluence_D2 / fluence_D1\n",
    "    ratio_err = ratio * (fluence_D1_err / fluence_D1 +\n",
    "                         fluence_D2_err / fluence_D2)\n",
    "\n",
    "    if debug:\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.suptitle(label)\n",
    "        gs = plt.GridSpec(3, 1)\n",
    "        ax1 = plt.subplot(gs[0])\n",
    "        ax2 = plt.subplot(gs[1], sharex=ax1)\n",
    "        axr = plt.subplot(gs[2], sharex=ax1)\n",
    "        ax1.errorbar(times, fluence_D1, yerr=fluence_D1_err, fmt='o', markersize=5)\n",
    "        ax2.errorbar(times, fluence_D2, yerr=fluence_D2_err, fmt='o', markersize=5)\n",
    "        axr.errorbar(times, ratio, yerr=ratio_err, fmt='o', markersize=5)\n",
    "\n",
    "    for lc_file in lc_files:\n",
    "        model_lc_table_fl = QTable(load_model_fluence(lc_file))\n",
    "        interpolated_lc_1 = interp1d(model_lc_table_fl['time'].to(u.s).value,\n",
    "                           model_lc_table_fl['fluence_D1'].value, fill_value=0,\n",
    "                           bounds_error=False)\n",
    "        interpolated_lc_2 = interp1d(model_lc_table_fl['time'].to(u.s).value,\n",
    "                           model_lc_table_fl['fluence_D2'].value, fill_value=0,\n",
    "                           bounds_error=False)\n",
    "        def interpolated_lc_ratio(time):\n",
    "            return(interpolated_lc_2(time) / interpolated_lc_1(time))\n",
    "    \n",
    "        def constant_fit_fun_1(x, a):\n",
    "            return a * interpolated_lc_1(x)\n",
    "        def constant_fit_fun_2(x, a):\n",
    "            return a * interpolated_lc_2(x)\n",
    "        def constant_fit_fun_ratio(x, a):\n",
    "            return a * interpolated_lc_ratio(x)\n",
    "        \n",
    "        par1, pcov1 = curve_fit(constant_fit_fun_1, \n",
    "                                times, fluence_D1, \n",
    "                                sigma=fluence_D1_err, p0=[1])\n",
    "        par2, pcov2 = curve_fit(constant_fit_fun_2, \n",
    "                                times, fluence_D2, \n",
    "                                sigma=fluence_D2_err, p0=[1])\n",
    "        parr, pcovr = curve_fit(constant_fit_fun_ratio, \n",
    "                                times, ratio, sigma=ratio_err, p0=[1])\n",
    "        \n",
    "        d1_chisq = red_chi_sq(constant_fit_fun_1(times, *par1), \n",
    "                              fluence_D1.value, fluence_D1_err.value, dof=len(fluence_D1) - 1)\n",
    "        d2_chisq = red_chi_sq(constant_fit_fun_2(times, *par2), \n",
    "                              fluence_D2.value, fluence_D2_err.value, dof=len(fluence_D2) - 1)\n",
    "        ratio_chisq = red_chi_sq(constant_fit_fun_ratio(times, *parr), \n",
    "                              ratio.value, ratio_err.value, dof=len(ratio) - 1)\n",
    "        \n",
    "        solutions.add_row({'model': lc_file, 'D1': par1, 'D2': par2, 'ratio': parr, \n",
    "                           'D1_chisq': d1_chisq, 'D2_chisq': d2_chisq, 'ratio_chisq': ratio_chisq,\n",
    "                           'ngood': len(fluence_D1)})\n",
    "        if debug:\n",
    "            fine_times = np.linspace(times[0], times[-1], 1000)\n",
    "            ax1.plot(fine_times, \n",
    "                     constant_fit_fun_1(fine_times, *par1), label=lc_file)\n",
    "            ax2.plot(fine_times, \n",
    "                     constant_fit_fun_2(fine_times, *par2), label=lc_file)\n",
    "            axr.plot(fine_times, \n",
    "                     constant_fit_fun_ratio(fine_times, *parr), label=lc_file)\n",
    "    if debug:\n",
    "        axr.set_ylabel('Flux ratio')\n",
    "        ax1.legend()\n",
    "    return solutions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_init = \\\n",
    "    get_lightcurve('shock_5e10.dat', exposure=300*u.s,  \n",
    "                   observing_windows=np.array([[1800, 30000]]) * u.s,\n",
    "                   distance=200*u.Mpc)\n",
    "lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=300*u.s, \n",
    "                                            final_resolution=1200*u.s, \n",
    "                                            silent=True)\n",
    "\n",
    "solutions = fit_lightcurve(lightcurve_rebin, label='shock_5e10.dat - 200 Mpc', \n",
    "                       debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightcurve_init = \\\n",
    "    get_lightcurve('kilonova_0.04.dat', exposure=300*u.s,  \n",
    "                   observing_windows=np.array([[1800, 40000]]) * u.s,\n",
    "                   distance=100*u.Mpc)\n",
    "lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=300*u.s, \n",
    "                                            final_resolution=6000*u.s, \n",
    "                                            silent=True)\n",
    "\n",
    "solutions = fit_lightcurve(lightcurve_rebin, label='kilonova_0.04.dat - 100 Mpc', \n",
    "                       debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebinned_lightcurve_fit(input_lc_file, exposure, label=None, debug=False,  \n",
    "                            observing_windows=np.array([[1800, 30000]]) * u.s, \n",
    "                            final_resolution=1200 * u.s, distance=100e6*u.pc,\n",
    "                            ntrial=100, outfile=None):\n",
    "    import seaborn as sns\n",
    "    import tqdm\n",
    "    from astroduet.utils import suppress_stdout\n",
    "    if outfile is not None and os.path.exists(outfile):\n",
    "        solutions = Table.read(outfile)\n",
    "    else:\n",
    "        solutions = None\n",
    "    for i in tqdm.tqdm(range(ntrial)):\n",
    "        try:\n",
    "            with suppress_stdout():\n",
    "                lightcurve_init = \\\n",
    "                    get_lightcurve(input_lc_file, exposure=exposure, observing_windows=observing_windows,\n",
    "                                   distance=distance)\n",
    "\n",
    "                lightcurve_rebin = lightcurve_through_image(lightcurve_init, exposure=exposure, \n",
    "                                                                final_resolution=final_resolution, \n",
    "                                                                debug=debug, silent=True)\n",
    "        \n",
    "            solutions = fit_lightcurve(lightcurve_rebin, label=input_lc_file, solutions=solutions,\n",
    "                                       debug=False)\n",
    "        except Exception as e:\n",
    "            print(\"An exception occurred. Intermediate results are saved in the solution Table\")\n",
    "            print(e)\n",
    "            break\n",
    "            \n",
    "    if outfile is not None:\n",
    "        solutions.write(outfile, overwrite=True)\n",
    "\n",
    "    return solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------**Uncomment below to produce the data**------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solutions_sh510_30 = get_rebinned_lightcurve_fit('shock_5e10.dat', exposure=300 * u.s,\n",
    "#                         observing_windows=np.array([[1800, 30000]]) * u.s,\n",
    "#                         distance=200 * u.Mpc, ntrial=100)\n",
    "\n",
    "# sns.pairplot(solutions_sh510_30.to_pandas(), hue='model', diag_kind=\"kde\", vars='D1_chisq,D2_chisq,ratio_chisq'.split(','))\n",
    "# solutions_sh510_30.write('solutions_sh510.csv', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure description: The fits with low chi squared are systematically those to the correct model (in this case, a shock-type GRB). We generated 30 light curves corresponding to the model `shock_5e10`, at 200 Mpc, starting 30 minutes after the event, and including all instrumental and zodiacal noise sources, and fitted it with all six GW models. The best-fit on the D1 and D2 light curve (as measured from low values of $\\chi^2$) is systematically the one corresponding to the correct model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ntrial = 10\n",
    "while 1:\n",
    "    solutions_sh510 = get_rebinned_lightcurve_fit('shock_5e10.dat', exposure=300 * u.s,\n",
    "                        observing_windows=np.array([[1800, 30000]]) * u.s,\n",
    "                        distance=200 * u.Mpc, ntrial=ntrial, outfile='solutions_sh510.csv')\n",
    "\n",
    "    solutions_k04 = get_rebinned_lightcurve_fit('kilonova_0.04.dat', exposure=300 * u.s,\n",
    "                            observing_windows=np.array([[1800, 40000]]) * u.s,\n",
    "                            final_resolution=6000 * u.s,\n",
    "                           distance=130*u.Mpc, ntrial=ntrial, outfile='solutions_k04.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(solutions_sh510.to_pandas(), hue='model', diag_kind=\"kde\", vars='D1_chisq,D2_chisq,ratio_chisq'.split(','))\n",
    "sns.pairplot(solutions_k04.to_pandas(), hue='model', diag_kind=\"kde\", vars='D1_chisq,D2_chisq,ratio_chisq'.split(','))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure description: Same as previous figure, but this time we simulated 30 lightcurves corresponding to the model `kilonova_0.04`, at 150 Mpc, starting 30 minutes after the event, including all instrumental and zodiacal noise sources, and fitted it with all six GW models. The best-fit on the D1 and D2 light curve (as measured from low values of $\\chi^2$), in this case, separates kilonova models from shock GRB models but not much different kilonova models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_distributions(solutions, correct, label=None, nbins=10):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.suptitle(label)\n",
    "    gs = plt.GridSpec(4, 1, height_ratios=(4, 3, 4, 3), hspace=0)\n",
    "    ax11 = plt.subplot(gs[0])\n",
    "    ax12 = plt.subplot(gs[1], sharex=ax11)\n",
    "    ax21 = plt.subplot(gs[2], sharex=ax11)\n",
    "    ax22 = plt.subplot(gs[3], sharex=ax11)\n",
    "    good = (solutions['D1_chisq'] < 1e32)&(solutions['D2_chisq'] < 1e32)&(solutions['ngood'] >= 4)\n",
    "    solutions = solutions[good]\n",
    "\n",
    "    if correct is not None:\n",
    "        ax1 = ax11\n",
    "        ax2 = ax21\n",
    "        good = solutions['model'] == correct\n",
    "        sol = solutions[good]\n",
    "        per_99_1 = np.percentile(sol['D1_chisq'], 99)\n",
    "        per_99_2 = np.percentile(sol['D2_chisq'], 99)\n",
    "        ax1.hist(sol['D1_chisq'], label=label, alpha=1, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "        ax2.hist(sol['D2_chisq'], label=label, alpha=1, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "        ax1.axvline(per_99_1, ls='--', lw=3, color='b')\n",
    "        ax2.axvline(per_99_2, ls='--', lw=3, color='b')\n",
    "\n",
    "    for label in sorted(list(set(solutions['model']))):\n",
    "        good = solutions['model'] == label\n",
    "        sol = solutions[good]\n",
    "        alpha=0.4\n",
    "        ax1 = ax12\n",
    "        ax2 = ax22\n",
    "        if correct is not None and label == correct:\n",
    "            continue\n",
    "        rej = np.count_nonzero(sol['D1_chisq'] > per_99_1) / len(sol['D1_chisq'])\n",
    "        ax1.hist(sol['D1_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "#                  bins=np.logspace(np.log10(np.min(sol['D1_chisq'])), np.log10(np.max(sol['D1_chisq'])), 10))\n",
    "        rej = np.count_nonzero(sol['D2_chisq'] > per_99_2) / len(sol['D2_chisq'])\n",
    "        ax2.hist(sol['D2_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                 bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "#                  bins=np.logspace(np.log10(np.min(sol['D2_chisq'])), np.log10(np.max(sol['D2_chisq'])), 10))\n",
    "#         axr.hist(sol['ratio_chisq'], label=label, alpha=alpha, density=True)\n",
    "    ax12.axvline(per_99_1, ls='--', lw=3, color='b', label='99% percentile')\n",
    "    ax22.axvline(per_99_2, ls='--', lw=3, color='b', label='99% percentile')\n",
    "\n",
    "    for ax in [ax11, ax12, ax21]:\n",
    "        ax.xaxis.set_visible(False)\n",
    "\n",
    "    for ax in [ax11, ax12, ax21, ax22]:\n",
    "#         ax.loglog()\n",
    "        ax.legend()\n",
    "        ax.semilogx()\n",
    "        ax.axvline(1, ls='--', lw=3, color='k', alpha=0.5)\n",
    "        ax.set_ylabel('Hist. Density')\n",
    "    ax22.set_xlabel(r'$\\chi^2_{\\rm red}$ (~1 indicates good fit)')\n",
    "    ax11.set_xlim([1, None])\n",
    "    return\n",
    "\n",
    "def plot_distributions_double(solutions, correct, label=None, nbins=10):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.suptitle(label)\n",
    "    gs = plt.GridSpec(4, 2, height_ratios=(4, 3, 4, 3), width_ratios=(1, 3), wspace=0.1, hspace=0)\n",
    "    for i in [0, 1]:\n",
    "        ax11 = plt.subplot(gs[0, i])\n",
    "        ax12 = plt.subplot(gs[1, i], sharex=ax11)\n",
    "        ax21 = plt.subplot(gs[2, i], sharex=ax11)\n",
    "        ax22 = plt.subplot(gs[3, i], sharex=ax11)\n",
    "        good = (solutions['D1_chisq'] < 1e32)&(solutions['D2_chisq'] < 1e32)&(solutions['ngood'] >= 4)\n",
    "        solutions = solutions[good]\n",
    "\n",
    "        if correct is not None:\n",
    "            ax1 = ax11\n",
    "            ax2 = ax21\n",
    "            good = solutions['model'] == correct\n",
    "            sol = solutions[good]\n",
    "            per_99_1 = np.percentile(sol['D1_chisq'], 99)\n",
    "            per_99_2 = np.percentile(sol['D2_chisq'], 99)\n",
    "            ax1.hist(sol['D1_chisq'], label=label, alpha=1, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "            ax2.hist(sol['D2_chisq'], label=label, alpha=1, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "            ax1.axvline(per_99_1, ls='--', lw=3, color='b')\n",
    "            ax2.axvline(per_99_2, ls='--', lw=3, color='b')\n",
    "\n",
    "        for label in sorted(list(set(solutions['model']))):\n",
    "            good = solutions['model'] == label\n",
    "            sol = solutions[good]\n",
    "            alpha=0.4\n",
    "            ax1 = ax12\n",
    "            ax2 = ax22\n",
    "            if correct is not None and label == correct:\n",
    "                continue\n",
    "            rej = np.count_nonzero(sol['D1_chisq'] > per_99_1) / len(sol['D1_chisq'])\n",
    "            ax1.hist(sol['D1_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D1_chisq']), np.max(sol['D1_chisq']), nbins))\n",
    "    #                  bins=np.logspace(np.log10(np.min(sol['D1_chisq'])), np.log10(np.max(sol['D1_chisq'])), 10))\n",
    "            rej = np.count_nonzero(sol['D2_chisq'] > per_99_2) / len(sol['D2_chisq'])\n",
    "            ax2.hist(sol['D2_chisq'], label=label + f' rej. {rej*100:.0f}%', alpha=alpha, density=True, \n",
    "                     bins=np.linspace(np.min(sol['D2_chisq']), np.max(sol['D2_chisq']), nbins))\n",
    "    #                  bins=np.logspace(np.log10(np.min(sol['D2_chisq'])), np.log10(np.max(sol['D2_chisq'])), 10))\n",
    "    #         axr.hist(sol['ratio_chisq'], label=label, alpha=alpha, density=True)\n",
    "        ax12.axvline(per_99_1, ls='--', lw=3, color='b', label='99% percentile')\n",
    "        ax22.axvline(per_99_2, ls='--', lw=3, color='b', label='99% percentile')\n",
    "    \n",
    "        for ax in [ax11, ax12, ax21]:\n",
    "            ax.xaxis.set_visible(False)\n",
    "\n",
    "        for ax in [ax11, ax12, ax21, ax22]:\n",
    "    #         ax.loglog()\n",
    "            if i == 1:\n",
    "                ax.legend()\n",
    "                ax.semilogx()\n",
    "            ax.axvline(1, ls='--', lw=3, color='k', alpha=0.5)\n",
    "            if i == 0:\n",
    "                ax.set_ylabel('Hist. Density')\n",
    "        ax22.set_xlabel(r'$\\chi^2_{\\rm red}$ (~1 indicates good fit)')\n",
    "        if i == 0:\n",
    "            ax11.set_xlim([0, max(per_99_1 + 1, per_99_2 + 1, 5)])\n",
    "        else:\n",
    "            ax11.set_xlim([1, None])\n",
    "    return\n",
    "\n",
    "solutions_sh510_30 = Table.read('solutions_sh510.csv')\n",
    "ntrials = len(solutions_sh510_30)//6\n",
    "good = solutions_sh510_30['D1_chisq'] > 0\n",
    "solutions_sh510_30 = solutions_sh510_30[good]\n",
    "ngood = len(solutions_sh510_30)//6\n",
    "plot_distributions(solutions_sh510_30, correct='shock_5e10.dat', \n",
    "                   label=f\"Shock 5e10 -- 200 Mpc -- {ntrials} trials ({ntrials - ngood} invalid)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions_k04 = Table.read('solutions_k04.csv')\n",
    "ntrials = len(solutions_k04)//6\n",
    "good = solutions_k04['D1_chisq'] > 0\n",
    "solutions_k04 = solutions_k04[good]\n",
    "ngood = len(solutions_k04)//6\n",
    "plot_distributions(solutions_k04, correct='kilonova_0.04.dat', \n",
    "                   label=f\"Kilonova 0.04 -- 130 Mpc -- {ntrials} trials ({ntrials - ngood} invalid)\", nbins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
